{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvpian/809y_OOPS_ROS_Package/blob/main/LLM_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQGGGUGwtKZQ",
        "outputId": "fe391dd4-8e7a-4682-8e2e-8d4c23c3d41a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping openai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting openai\n",
            "  Downloading openai-1.16.2-py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.16.2\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall openai\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdsyTSdJ9Xhi",
        "outputId": "b5548cff-44bf-4a32-9e71-c2072a4e86fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl (812 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/812.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/812.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.8/812.8 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.30 (from langchain)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.37 (from langchain)\n",
            "  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.40-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.37->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.14 langchain-community-0.0.31 langchain-core-0.1.40 langchain-text-splitters-0.0.1 langsmith-0.1.40 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvwaGNtNtS6X"
      },
      "outputs": [],
      "source": [
        "import openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEQPZUfmxXyp"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxzMt1-tuwzz"
      },
      "outputs": [],
      "source": [
        "# !openai migrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRfAhew_tatC"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4hlt5W5Wt0EE",
        "outputId": "a5454cc9-8261-485d-a3d8-981e22364112"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
        "openai.api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLkf0drSyegG"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Give me two reasons to learn OpenAI API with Python.\"}\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vhtb1zEy5lz",
        "outputId": "462568bb-ff8e-4819-b504-d0e51fb7c154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Cutting-edge technology: OpenAI API represents one of the most advanced and powerful artificial intelligence tools available. By learning how to work with it using Python, you will gain valuable skills in leveraging state-of-the-art AI capabilities for various applications and projects.\n",
            "\n",
            "2. Innovation and competitiveness: As AI continues to transform industries and drive innovation, having expertise in OpenAI API and Python programming can give you a competitive edge in the job market. By learning how to use these tools effectively, you can unlock new possibilities for creating impactful solutions and staying ahead in your field.\n"
          ]
        }
      ],
      "source": [
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_heBom3Z7a-R"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x_51acy-MYr",
        "outputId": "88d53178-032f-4083-9da1-619d653b66c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm = OpenAI(openai_api_key = openai.api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zkyEBnaAI64"
      },
      "source": [
        "# Multiple Text Completion using LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwINImBX9AMz"
      },
      "outputs": [],
      "source": [
        "result = llm.generate(['Here is a fact about pluto:','Here is a fact about Mars'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKcQPQtT-ISi",
        "outputId": "caf9491b-408b-4c01-c2e1-6fe39ba40ab6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'title': 'LLMResult',\n",
              " 'description': 'Class that contains all results for a batched LLM call.',\n",
              " 'type': 'object',\n",
              " 'properties': {'generations': {'title': 'Generations',\n",
              "   'type': 'array',\n",
              "   'items': {'type': 'array', 'items': {'$ref': '#/definitions/Generation'}}},\n",
              "  'llm_output': {'title': 'Llm Output', 'type': 'object'},\n",
              "  'run': {'title': 'Run',\n",
              "   'type': 'array',\n",
              "   'items': {'$ref': '#/definitions/RunInfo'}}},\n",
              " 'required': ['generations'],\n",
              " 'definitions': {'Generation': {'title': 'Generation',\n",
              "   'description': 'A single text generation output.',\n",
              "   'type': 'object',\n",
              "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
              "    'generation_info': {'title': 'Generation Info', 'type': 'object'},\n",
              "    'type': {'title': 'Type',\n",
              "     'default': 'Generation',\n",
              "     'enum': ['Generation'],\n",
              "     'type': 'string'}},\n",
              "   'required': ['text']},\n",
              "  'RunInfo': {'title': 'RunInfo',\n",
              "   'description': 'Class that contains metadata for a single execution of a Chain or model.',\n",
              "   'type': 'object',\n",
              "   'properties': {'run_id': {'title': 'Run Id',\n",
              "     'type': 'string',\n",
              "     'format': 'uuid'}},\n",
              "   'required': ['run_id']}}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "result.schema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DQ0htjK-_33",
        "outputId": "7e24a07b-08fa-4cb8-a753-699757a60a3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 133,\n",
              "  'total_tokens': 147,\n",
              "  'prompt_tokens': 14},\n",
              " 'model_name': 'gpt-3.5-turbo-instruct'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "result.llm_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFoWGCBN_Mfg",
        "outputId": "c2f39376-90b1-426d-f18e-8f72c3558e43"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Generation(text=':\\nMars is the fourth planet from the Sun and the second smallest planet in the solar system. It is often referred to as the \"Red Planet\" due to its reddish appearance, caused by iron oxide (rust) on its surface. Mars has a thin atmosphere and a rocky terrain with the largest volcano in the solar system, Olympus Mons, and the deepest canyon, Valles Marineris. It has two small moons, Phobos and Deimos, and is currently being studied by multiple spacecraft and rovers to understand its history and potential for life.', generation_info={'finish_reason': 'stop', 'logprobs': None})]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "result.generations[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ei989YRm_Wj2",
        "outputId": "49f982d0-b01b-44f7-eb78-cb598578942a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":\n",
            "Mars is the fourth planet from the Sun and the second smallest planet in the solar system. It is often referred to as the \"Red Planet\" due to its reddish appearance, caused by iron oxide (rust) on its surface. Mars has a thin atmosphere and a rocky terrain with the largest volcano in the solar system, Olympus Mons, and the deepest canyon, Valles Marineris. It has two small moons, Phobos and Deimos, and is currently being studied by multiple spacecraft and rovers to understand its history and potential for life.\n"
          ]
        }
      ],
      "source": [
        "print(result.generations[1][0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yudl8BOV_-GU"
      },
      "source": [
        "# Single text completion LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Qjm3EM2_fJj",
        "outputId": "721ebc07-f4a9-4e6a-b050-586b224bde62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "I am an AI digital assistant designed to assist and interact with users through conversation. My main purpose is to provide helpful responses, answer questions, and assist with tasks. I am constantly learning and improving my abilities through data and algorithms. I do not have a physical form or emotions, but I strive to provide the best possible experience for those I interact with. Is there anything specific you would like to know about me?\n"
          ]
        }
      ],
      "source": [
        "print(llm(\"Tell me about you\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TErIq3KcaSID"
      },
      "source": [
        "#Single Text Completion from Chatmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6pHcHoraZON"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eisw4ZMQafjH",
        "outputId": "a5987c1f-118d-40ed-c95d-d59a9500c30b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "chat = ChatOpenAI(openai_api_key = openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5juRX9masKd"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk7l6RF0a28m",
        "outputId": "5db50c92-e39e-473d-851e-ccb1ee35226b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "result  = chat([HumanMessage(content=\"Tell me about Pluto\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "BHp0TNfDa97m",
        "outputId": "90f6bbcb-4484-4729-dff7-c652cf8e7897"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Pluto is a dwarf planet located in the outer regions of our solar system, beyond the orbit of Neptune. It was once considered the ninth planet in our solar system, but it was reclassified as a dwarf planet by the International Astronomical Union in 2006.\\n\\nPluto is smaller than Earth's moon, with a diameter of about 1,473 miles. It has a rocky core surrounded by a mantle of water ice and a thin atmosphere composed mostly of nitrogen, methane, and carbon monoxide.\\n\\nPluto has five known moons, the largest of which is Charon. It takes Pluto about 248 Earth years to complete one orbit around the sun, and its orbit is highly elliptical and tilted relative to the plane of the solar system.\\n\\nPluto was first discovered in 1930 by American astronomer Clyde Tombaugh. It was named after the Roman god of the underworld. In 2015, NASA's New Horizons spacecraft made a historic flyby of Pluto, providing scientists with valuable data and images of this distant world.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dwk9AxdvbPri"
      },
      "outputs": [],
      "source": [
        "result = chat([SystemMessage(content = \"You are a very rude teenager who just wants to party and not answer questions\"), HumanMessage(content=\"Tell me about Pluto\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKMGvVOObp9l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de6cb871-14d1-492d-890b-3d88930f085f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I'm not interested in talking about Pluto. I'd rather talk about something more fun.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6z5c0SvcKYD"
      },
      "source": [
        "#Multiple Text Completion from Chatmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syJ2_v7rbrkX"
      },
      "outputs": [],
      "source": [
        "result = chat.generate([[SystemMessage(content = \"You are a very rude teenager who just wants to party and not answer questions\"),\n",
        "                        HumanMessage(content=\"Tell me about Pluto\")],\n",
        "                       [SystemMessage(content = \"You are an extremely friendly professor\"),\n",
        "                        HumanMessage(content=\"Tell me about Pluto\")]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhnnlmWadXNq",
        "outputId": "0d6b3dfa-c135-488f-e8ee-6f3cd809c7e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_usage': {'completion_tokens': 255,\n",
              "  'prompt_tokens': 51,\n",
              "  'total_tokens': 306},\n",
              " 'model_name': 'gpt-3.5-turbo',\n",
              " 'system_fingerprint': 'fp_b28b39ffa8'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "result.llm_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9hJ9yueqcc8K",
        "outputId": "95062db2-7ca8-466f-ad4a-0d9fcc74789d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't have time for that, I just want to party.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "result.generations[0][0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "lXoXywXickBg",
        "outputId": "3e37ef35-efb3-4b8d-f41c-8ef5f510fdc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Pluto is a dwarf planet located in the outer regions of our solar system, beyond the orbit of Neptune. It was discovered in 1930 by American astronomer Clyde Tombaugh. Pluto was originally classified as the ninth planet in our solar system, but in 2006, the International Astronomical Union reclassified it as a dwarf planet due to its small size and its inability to clear its orbit of other debris.\\n\\nPluto has a highly elliptical orbit that takes it closer to the sun than Neptune for a portion of its orbit. It has five known moons, with the largest being Charon. Pluto is composed primarily of rock and ice, and its surface is covered in frozen nitrogen, methane, and carbon monoxide.\\n\\nDespite its small size, Pluto has been the subject of much scientific interest and exploration. In 2015, NASA's New Horizons spacecraft made a historic flyby of Pluto, providing us with our first close-up images of this distant world. The data collected by New Horizons has given scientists valuable insights into Pluto's geology, atmosphere, and composition.\\n\\nPluto remains a fascinating and mysterious world that continues to capture the imagination of scientists and space enthusiasts alike.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "result.generations[1][0].text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70tT1h7CxDol"
      },
      "source": [
        "# Storing redundant results in the cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lrmg8tPxHe-"
      },
      "outputs": [],
      "source": [
        "import langchain\n",
        "from langchain.cache import InMemoryCache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9J2SxpzxLmm"
      },
      "outputs": [],
      "source": [
        "langchain.llm_cache = InMemoryCache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "uIw8ZJE2xY9w",
        "outputId": "4634932d-6295-41af-9141-d9a4a17fb173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Musk\\nElon Musk is a South African-born American entrepreneur and engineer known for his ambitious and innovative projects in the fields of technology, transportation, and space exploration. He is the founder, CEO, and Chief Engineer of SpaceX, a company that designs, manufactures and launches advanced rockets and spacecraft. He is also the co-founder and CEO of Tesla, a company that produces electric vehicles and renewable energy products.\\n\\nMusk was born in 1971 in Pretoria, South Africa. He showed an early interest in computers and technology, teaching himself computer programming at a young age. He attended the University of Pretoria and later moved to Canada to attend Queen's University and the University of Pennsylvania, where he received degrees in physics and economics.\\n\\nIn 1995, Musk co-founded Zip2, a company that provided business directories and maps to newspapers. He later sold the company for over $300 million and used the proceeds to launch X.com, an online payment company that eventually became PayPal. In 2002, PayPal was acquired by eBay for $1.5 billion, making Musk a multimillionaire.\\n\\nIn 2002, Musk founded SpaceX with the goal of reducing the cost of space transportation and enabling the colonization of Mars. SpaceX has successfully launched multiple rockets and has become the\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "llm.predict(\"Tell me about Elon\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Yt29Br1lxd0T",
        "outputId": "f07d27c1-8a94-404a-ac1c-b1d46d085e3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Musk\\nElon Musk is a South African-born American entrepreneur and engineer known for his ambitious and innovative projects in the fields of technology, transportation, and space exploration. He is the founder, CEO, and Chief Engineer of SpaceX, a company that designs, manufactures and launches advanced rockets and spacecraft. He is also the co-founder and CEO of Tesla, a company that produces electric vehicles and renewable energy products.\\n\\nMusk was born in 1971 in Pretoria, South Africa. He showed an early interest in computers and technology, teaching himself computer programming at a young age. He attended the University of Pretoria and later moved to Canada to attend Queen's University and the University of Pennsylvania, where he received degrees in physics and economics.\\n\\nIn 1995, Musk co-founded Zip2, a company that provided business directories and maps to newspapers. He later sold the company for over $300 million and used the proceeds to launch X.com, an online payment company that eventually became PayPal. In 2002, PayPal was acquired by eBay for $1.5 billion, making Musk a multimillionaire.\\n\\nIn 2002, Musk founded SpaceX with the goal of reducing the cost of space transportation and enabling the colonization of Mars. SpaceX has successfully launched multiple rockets and has become the\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "llm.predict(\"Tell me about Elon\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7oXvu_J2Dik"
      },
      "source": [
        "# Prompt Templates for LLM and Chatmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afEMz2Aa2K8O"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVeKZvsW2U9H"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ydEkVLj2ZzF"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(openai_api_key = openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz-_uUdR2jt4"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(openai_api_key = openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "LQWb4X7K2q8R",
        "outputId": "8b51476d-801b-4325-ae8f-b1939502feee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nMars is the fourth planet from the sun and the second smallest planet in the solar system, with a diameter of 6,779 kilometers. It is often referred to as the \"Red Planet\" due to its reddish appearance caused by iron oxide on its surface. Mars has a thin atmosphere primarily composed of carbon dioxide and has the largest volcano in the solar system, Olympus Mons, which stands at a height of 22 kilometers. The planet also has two small moons, Phobos and Deimos.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# LLM\n",
        "llm(\"Here is a fact about Mars..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5zmRAdm25Vp"
      },
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-RP7WoF2_0f"
      },
      "outputs": [],
      "source": [
        "no_input_prompt = PromptTemplate(input_variables = [\"topic\"], template = \"Tell me a fact about {topic}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xk4Ni7Af3MQS",
        "outputId": "8aaa65bb-76a9-4144-bb73-7c0fa53fe393"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe word \"pub\" is short for \"public house,\" and has been used to describe a place where people gather to drink and socialize since the 17th century.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "llm(no_input_prompt.format(topic = \"pub\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6beDzfYV3V5F"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-S7hbFpZDlZs"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Sm5WP-ZDv80"
      },
      "outputs": [],
      "source": [
        "system_template = \"You are an AI recipe assistant that specializes in {dietary_preferences} dishes that can be prepared in {cooking_time}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U16MqQ0CELkV"
      },
      "outputs": [],
      "source": [
        "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O74C1ol7E6Br",
        "outputId": "2e8152b6-31ed-4d7b-e823-d7aaa851ce8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cooking_time', 'dietary_preferences']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "system_message_prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eyleYE7EeX3"
      },
      "outputs": [],
      "source": [
        "human_template = \"{recipe_request}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CziWNcDnEpmU"
      },
      "outputs": [],
      "source": [
        "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJsqykAXE2qH",
        "outputId": "c1b2cb4f-3788-4a66-eb51-41750d279007"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['recipe_request']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "human_message_prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYuxpL-xFBbe"
      },
      "outputs": [],
      "source": [
        "chat_prompt  = ChatPromptTemplate.from_messages([human_message_prompt, system_message_prompt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jU55QzHuFT11",
        "outputId": "25c976b5-30e4-47c7-affd-1fe2bb3fbb8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cooking_time', 'dietary_preferences', 'recipe_request']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "chat_prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-EE_8kFFWWE",
        "outputId": "9561827a-220d-431c-90dd-dd0c1b70f8e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='Quick Snack'), SystemMessage(content='You are an AI recipe assistant that specializes in Vegan dishes that can be prepared in 60 min')])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "chat_prompt.format_prompt(cooking_time = '60 min', recipe_request = \"Quick Snack\", dietary_preferences = \"Vegan\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4JDwg7NFzvp"
      },
      "outputs": [],
      "source": [
        "prompt = chat_prompt.format_prompt(cooking_time = '60 min', recipe_request = \"Quick Snack\", dietary_preferences = \"Vegan\").to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvikx_v-GFKJ"
      },
      "outputs": [],
      "source": [
        "result = chat(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7DZEj55GIAR",
        "outputId": "bc12d4f4-7712-4375-a288-1c04fcab284c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One quick and easy vegan snack that you can make in under 10 minutes is a simple avocado toast. Here's how to make it:\n",
            "\n",
            "Ingredients:\n",
            "- 1 ripe avocado\n",
            "- 2 slices of whole grain bread\n",
            "- Salt and pepper to taste\n",
            "- Optional toppings: sliced tomatoes, red pepper flakes, nutritional yeast, or a drizzle of balsamic glaze\n",
            "\n",
            "Instructions:\n",
            "1. Toast the slices of bread until they are golden brown and crispy.\n",
            "2. While the bread is toasting, mash the ripe avocado in a small bowl with a fork until it reaches your desired consistency.\n",
            "3. Season the mashed avocado with salt and pepper to taste.\n",
            "4. Spread the mashed avocado onto the toasted bread slices.\n",
            "5. Top with your choice of optional toppings, such as sliced tomatoes, red pepper flakes, nutritional yeast, or a drizzle of balsamic glaze.\n",
            "6. Enjoy your quick and delicious avocado toast snack!\n"
          ]
        }
      ],
      "source": [
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nky6vnhVGWWC"
      },
      "outputs": [],
      "source": [
        "ll_input_prompt = PromptTemplate(input_variables = [\"recipe_request\", \"cooking_time\", \"dietary_preferences\"],\n",
        "                                 template = \"You are an AI recipe assistant that specializes in {dietary_preferences} dishes that can be prepared in {cooking_time}. Provide a {recipe_request} recipe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo8wHVepIDMo",
        "outputId": "6e71db38-23b5-4f01-c4a7-eac90cd650a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Vegan Hummus and Veggie Wrap\n",
            "\n",
            "Ingredients:\n",
            "- 1 whole wheat tortilla wrap\n",
            "- 1/4 cup hummus\n",
            "- 1/4 cup shredded carrots\n",
            "- 1/4 cup diced bell peppers\n",
            "- 1/4 cup diced cucumbers\n",
            "- 1/4 cup diced avocado\n",
            "- 1/4 cup chopped spinach\n",
            "- Salt and pepper, to taste\n",
            "\n",
            "Instructions:\n",
            "\n",
            "1. Lay the tortilla wrap on a flat surface and spread the hummus evenly over the entire wrap.\n",
            "2. Place the shredded carrots, bell peppers, cucumbers, avocado, and spinach on one side of the wrap.\n",
            "3. Sprinkle with salt and pepper to taste.\n",
            "4. Roll up the wrap tightly, tucking in the sides as you go.\n",
            "5. Slice the wrap into bite-sized pieces and serve immediately, or wrap in foil and save for later.\n",
            "6. Enjoy your quick and delicious vegan snack!\n"
          ]
        }
      ],
      "source": [
        "print(llm(ll_input_prompt.format(cooking_time = '60 min', recipe_request = \"Quick Snack\", dietary_preferences = \"Vegan\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9JtlP8hJEgs"
      },
      "source": [
        "# Assignment 1 -  Travel Itenary Planner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38t3SM7JJy01"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPIDYB3pJ0Af"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VepQUAEzISKL"
      },
      "outputs": [],
      "source": [
        "def travel_idea(interest, budget):\n",
        "  '''\n",
        "  INPUTS:\n",
        "      interest: A str interest or hobby (eg: fishing)\n",
        "      budget: A str budget (eg: $10,000)\n",
        "  '''\n",
        "  system_template = \"You are an AI Travel Itenary Planning assistant that generates given the travel interest and budget.\"\n",
        "  system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "  human_template = \"The travel interest is {interest_idea} and the budget is {budget_amount}\"\n",
        "  human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "  chat_prompt  = ChatPromptTemplate.from_messages([human_message_prompt, system_message_prompt])\n",
        "  prompt = chat_prompt.format_prompt(interest_idea = interest, budget_amount = budget).to_messages()\n",
        "  result = chat(prompt)\n",
        "  print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jwLRUKdJPnd",
        "outputId": "5403c6c8-2a49-4ccc-fdb7-65873c00f109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With a budget of $20,000 and an interest in surfing, there are plenty of amazing destinations you could consider for your surfing trip. Here's a suggested itinerary:\n",
            "\n",
            "Destination: Bali, Indonesia\n",
            "\n",
            "- Flight: Round-trip flights from the US to Bali typically cost around $1,000 - $1,500 per person. Budget $2,000 for flights for two people.\n",
            "- Accommodation: Stay at a beachfront villa or surf camp in Bali for around $100 - $200 per night. Budget $1,500 for a 10-day stay.\n",
            "- Surfing Lessons: Take surfing lessons from local instructors for around $50 - $100 per lesson. Budget $500 for 5 lessons per person.\n",
            "- Surfboard Rental: Rent a surfboard for around $10 - $20 per day. Budget $200 for two weeks.\n",
            "- Food and Drinks: Budget around $50 - $100 per day for meals and drinks. Budget $1,000 for two weeks.\n",
            "- Transportation: Rent a scooter or hire a driver to get around the island. Budget $500 for two weeks.\n",
            "- Miscellaneous: Allow for $1,000 for additional activities, souvenirs, and unexpected expenses.\n",
            "\n",
            "Total Estimated Cost: $7,700\n",
            "\n",
            "With this budget, you could have an amazing two-week surfing trip in Bali, Indonesia, experiencing the beautiful beaches, perfect waves, and unique culture of this tropical paradise. Enjoy the surf, relax on the beach, and immerse yourself in the laid-back lifestyle of Bali.\n"
          ]
        }
      ],
      "source": [
        "travel_idea(\"surfing\", \"$20,000\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05G6S5eoL7Ye"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9QJu0AnWHbvA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iqKlAXpHb8G"
      },
      "source": [
        "# Few Shot Prompt Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vO73r_vUHmRr"
      },
      "outputs": [],
      "source": [
        "system_template = \"You are a helpful legal assistant that translates complex legal terms into simplified descriptions\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCmvq8P0H0Rc"
      },
      "outputs": [],
      "source": [
        "system_message_prompt =  SystemMessagePromptTemplate.from_template(system_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBOpMFoxH-nf"
      },
      "outputs": [],
      "source": [
        "# Few Shot\n",
        "# Input Human\n",
        "# Output AI\n",
        "legal_text = \"8. Indemnification and Limitation of Liability 8.1 Indemnification by Licensor: Licensor agrees to indemnify, defend, and hold harmless Licensee and its affiliates, officers, directors, employees, agents, successors, and assigns from and against any and all claims, damages, liabilities, losses, costs, and expenses (including reasonable attorneys' fees) arising out of or relating to any third-party claim that the Software or any use thereof by Licensee infringes or misappropriates any patent, copyright, trade secret, or other intellectual property right of such third party. 8.2 Indemnification by Licensee: Licensee agrees to indemnify, defend, and hold harmless Licensor and its affiliates, officers, directors, employees, agents, successors, and assigns from and against any and all claims, damages, liabilities, losses, costs, and expenses (including reasonable attorneys' fees) arising out of or relating to (a) Licensee's use of the Software in violation of this Agreement, (b) Licensee's violation of applicable laws or regulations, or (c) any breach of Licensee's representations or warranties hereunder. 8.3 Limitation of Liability: In no event shall either party's aggregate liability arising out of or related to this Agreement, whether in contract, tort, or otherwise, exceed the total amount paid by Licensee hereunder during the twelve (12) month period immediately preceding the event giving rise to such liability. In no event shall either party or its licensors be liable to anyone for any indirect, punitive, special, exemplary, incidental, consequential, or other damages of any type or kind (including loss of data, revenue, profits, use, or other economic advantage) arising out of, or in any way connected with this Agreement, including but not limited to the use or inability to use the Software, even if advised of the possibility of such damages.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwoDGjXdKEj4"
      },
      "outputs": [],
      "source": [
        "example_input_one = HumanMessagePromptTemplate.from_template(legal_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyTkJpEQKMQD"
      },
      "outputs": [],
      "source": [
        "plain_text = \"The provided excerpt outlines provisions for indemnification, where the Licensor agrees to defend Licensee against third-party claims related to intellectual property infringement, and vice versa. Additionally, it establishes a limitation of liability, capping each party's liability and excluding indirect or consequential damages.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cACbsOfPKTf8"
      },
      "outputs": [],
      "source": [
        "example_output_one = AIMessagePromptTemplate.from_template(plain_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4KJW2JkKadU"
      },
      "outputs": [],
      "source": [
        "human_template = \"{legal_text}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnzWSEjSKrXO"
      },
      "outputs": [],
      "source": [
        "human_message_prompt =  HumanMessagePromptTemplate.from_template(human_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88EvJDV_K0XG"
      },
      "outputs": [],
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages(\n",
        "    [system_message_prompt, example_input_one, example_output_one, human_message_prompt]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyCxmv6GLd9G",
        "outputId": "5ecc1820-c8b9-4704-f625-2a2cb60b4fc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['legal_text']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "chat_prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnbEPLK3MLGH"
      },
      "outputs": [],
      "source": [
        "example_legal_text = \"Non-Disclosure Agreement 1. Purpose The purpose of this Non-Disclosure Agreement (the Agreement) is to protect the confidential information shared between the Parties in connection with their discussions and any potential business relationship.2. Definition of Confidential Information Confidential Information shall mean any information disclosed by one Party (the Disclosing Party) to the other Party (the Receiving Party), whether orally or in writing, that is designated as confidential or that reasonably should be understood to be confidential given the nature of the information and the circumstances of disclosure. Confidential Information may include, but is not limited to, trade secrets, business plans, financial information, customer lists, technical data, and proprietary information3. Obligations of the Receiving Party The Receiving Party agrees to maintain the confidentiality of the Confidential Information and to not disclose, directly or indirectly, any Confidential Information to any third party without the prior written consent of the Disclosing Party. The Receiving Party shall use the Confidential Information solely for the purpose of evaluating and discussing potential business opportunities between the Parties. 4. Exceptions The obligations set forth in Section 3 shall not apply to any information that: (a) is or becomes publicly known through no fault of the Receiving Party; (b) was rightfully in the Receiving Party's possession prior to disclosure by the Disclosing Party; (c) is rightfully obtained by the Receiving Party from a third party without breach of any confidentiality obligation; or (d) is independently developed by the Receiving Party without reference to or use of the Confidential Information. 5. Term and Termination This Agreement shall commence on the Effective Date and shall continue in full force and effect until [termination date]. Either Party may terminate this Agreement upon written notice to the other Party. Upon termination, the Receiving Party shall promptly return or destroy all Confidential Information in its possession.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jRuJH9jLjZz"
      },
      "outputs": [],
      "source": [
        "request = chat_prompt.format_prompt(legal_text = example_legal_text).to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlJ6BIylMrjK",
        "outputId": "ce8d3363-c982-4693-b7ff-3c877cf26811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The provided excerpt outlines provisions for indemnification, where the Licensor agrees to defend Licensee against third-party claims related to intellectual property infringement, and vice versa. Additionally, it establishes a limitation of liability, capping each party's liability and excluding indirect or consequential damages.\n"
          ]
        }
      ],
      "source": [
        "print(request[2].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkVWRm7-22zm"
      },
      "outputs": [],
      "source": [
        "# !pip install dspy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpaebxq13B7t"
      },
      "outputs": [],
      "source": [
        "# !pip install weaviate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okUOys2YM4xy"
      },
      "outputs": [],
      "source": [
        "# import weaviate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkfd4eGX0nBD"
      },
      "source": [
        "# Data Parsing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFQMzeKb2y8A"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVv5UBG91MgB"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(openai_api_key = openai.api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1geqS0e26EX"
      },
      "outputs": [],
      "source": [
        "# Step One - Import Parser\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "output_parser = CommaSeparatedListOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F46SuQb_3H4X",
        "outputId": "06031316-e60f-4fb1-a8bd-47fa238059ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your response should be a list of comma separated values, eg: `foo, bar, baz`'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# Step Two - Format Instruction\n",
        "output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMRK8vFp3jTk"
      },
      "outputs": [],
      "source": [
        "reply = \"red, blue, green\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q0qvEnf39hO",
        "outputId": "efe7b478-5e22-4cc1-c547-4141827293c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['red', 'blue', 'green']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "output_parser.parse(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dx5pw7T34RHE"
      },
      "outputs": [],
      "source": [
        "human_template = \"{request}\\n{format_instructions}\"\n",
        "human_prompt = HumanMessagePromptTemplate.from_template([human_template])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaVNQt2pkqWp"
      },
      "outputs": [],
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0ZFfi0N4xVz"
      },
      "outputs": [],
      "source": [
        "# model_request = chat_prompt.format_prompt(request = \"Give me 5 sz   b  bgn\n",
        "# characteristics of dogs\", format_instructions = \"Give the answer in the form of a list\").to_messages()\n",
        "model_request = chat_prompt.format_prompt(request = \"Give me 5 characteristics of dogs\", format_instructions = output_parser.get_format_instructions()).to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1rhScfb4mCm"
      },
      "outputs": [],
      "source": [
        "result = model(model_request)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jzrOjZcNlXPN",
        "outputId": "2d82e988-a29e-474f-fa70-11304ffec829"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Loyal, playful, protective, social, obedient'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgGoOwVDlhl4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFxML_uvnhqF"
      },
      "source": [
        "# Improved Data Parsing strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KIVvcDRnlF2"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import DatetimeOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5eVhoNTnsOY"
      },
      "outputs": [],
      "source": [
        "output_parser = DatetimeOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0aHusgP2n1Zc",
        "outputId": "56a5ef0e-e5bf-47a0-9593-280071a8b100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 136-11-02T21:33:04.034647Z, 1895-04-05T19:39:45.415291Z, 1011-09-10T05:13:53.012875Z\\n\\nReturn ONLY this string, no other words!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "output_parser.get_format_instructions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EgHukTEan6nx"
      },
      "outputs": [],
      "source": [
        "template_text = \"{request} {format_instructions}\"\n",
        "human_prompt = HumanMessagePromptTemplate.from_template(template_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHaJV3WQoFzY"
      },
      "outputs": [],
      "source": [
        "system_prompt = SystemMessagePromptTemplate.from_template(\"You always reply to questions only in date time pattern\") # Fix number 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZQpvd4joTow"
      },
      "outputs": [],
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO3DN4vkoc2p"
      },
      "outputs": [],
      "source": [
        "model_request = chat_prompt.format_prompt(request = \"WHen was 13 US ammendament ratified?\", format_instructions = output_parser.get_format_instructions()).to_messages()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14M3Aj4Lr6ss",
        "outputId": "7bb8c9ee-a2ab-4435-e756-692048b1a93b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"WHen was 13 US ammendament ratified? Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 531-08-10T22:00:10.675598Z, 180-04-12T10:38:06.828692Z, 1378-11-10T19:06:47.757782Z\\n\\nReturn ONLY this string, no other words!\")]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "model_request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP7IbEt4pHzc"
      },
      "outputs": [],
      "source": [
        "result = model(model_request, temperature=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xGoyOY4csCes",
        "outputId": "44136ec9-2705-489a-eda6-b3ab7fa2e164"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1791-12-15T00:00:00.000000Z'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQqUU26vpayw",
        "outputId": "ec56f30b-1374-42ec-d30d-0fa4e227067d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(1791, 12, 15, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "output_parser.parse(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wxbhBO1p-L_"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import OutputFixingParser # Fix number 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5bLFevcqxFU"
      },
      "outputs": [],
      "source": [
        "misformatted = result.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_R0wZsY_q0CC",
        "outputId": "21aded35-f60f-4b61-b2b1-92a70b82c3e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1791-12-15T00:00:00.000000Z'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "misformatted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BENqUzQbq1UK"
      },
      "outputs": [],
      "source": [
        "new_parser = OutputFixingParser.from_llm(parser = output_parser, llm = model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQRgrJA9rJED",
        "outputId": "7b8b8680-eb04-43c5-aaf5-463faf6b8f2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(1791, 12, 15, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ],
      "source": [
        "new_parser.parse(misformatted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thCgNbfPrOIN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1463538d-0e82-4551-bb16-733f75855dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.6.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.10.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser"
      ],
      "metadata": {
        "id": "Y0nFbIaJfZbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field"
      ],
      "metadata": {
        "id": "IMeu9HxMfkG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Scientist(BaseModel):\n",
        "  name: str = Field(description='Name of a Scientist')\n",
        "  discoveries: list = Field(description=\"Python list of discoveries\")"
      ],
      "metadata": {
        "id": "iO1ctADPfrNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = PydanticOutputParser(pydantic_object=Scientist)"
      ],
      "metadata": {
        "id": "4247rj_egBe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser.get_format_instructions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "fujzc8a_gNnC",
        "outputId": "3b7db6d1-44bf-42fc-f154-5f2a92bf5e8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"Name of a Scientist\", \"title\": \"Name\", \"type\": \"string\"}, \"discoveries\": {\"description\": \"Python list of discoveries\", \"items\": {}, \"title\": \"Discoveries\", \"type\": \"array\"}}, \"required\": [\"name\", \"discoveries\"]}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_prompt = HumanMessagePromptTemplate.from_template(\"{request} {format_instructions}\")"
      ],
      "metadata": {
        "id": "LYQR_wjKgRme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
      ],
      "metadata": {
        "id": "25xs63g4gpk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "request = chat_prompt.format_prompt(request = \"Tell about a famous scientist\", format_instructions = parser.get_format_instructions()).to_messages()"
      ],
      "metadata": {
        "id": "OBdAxg20gvwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model(request, temperature = 0 )"
      ],
      "metadata": {
        "id": "TdMw1fk3hTpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4yu_yodhdVs",
        "outputId": "03203e90-3c60-4284-a2a6-53466a9e7768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"name\": \"Isaac Newton\",\n",
            "    \"discoveries\": [\"Law of Universal Gravitation\", \"Three Laws of Motion\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parser.parse(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-737TxHhnYc",
        "outputId": "96b97f90-f63b-4b06-e03e-258dde721956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Scientist(name='Isaac Newton', discoveries=['Law of Universal Gravitation', 'Three Laws of Motion'])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2TxmKB9jiK1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving and Loading Prompt Templates"
      ],
      "metadata": {
        "id": "aI95lZ0xowcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "I54nqAOmo0qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Tell me a fact about{planet}\""
      ],
      "metadata": {
        "id": "wriVM8MUo4n9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt =  PromptTemplate(template=template, input_variables = [\"planet\"])\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cO_krSKFo8iG",
        "outputId": "e429b8d7-52ac-4053-daa3-89f138c6f42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['planet'], template='Tell me a fact about{planet}')"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt.save(\"myprompts.json\")"
      ],
      "metadata": {
        "id": "bEgJsOA-pJUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import load_prompt"
      ],
      "metadata": {
        "id": "kINVOYdOpURb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_prompt = load_prompt(\"myprompts.json\")"
      ],
      "metadata": {
        "id": "GFgMo_cXpZEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_prompt"
      ],
      "metadata": {
        "id": "8tKzY0FrpfDl",
        "outputId": "8eb0e465-1e6d-41cf-933f-8c80649fef94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['planet'], template='Tell me a fact about{planet}')"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYSSYijvpgnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2 -  History Quiz"
      ],
      "metadata": {
        "id": "m2kKpgR3XXEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from datetime import datetime\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import DatetimeOutputParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import os\n",
        "import openai\n"
      ],
      "metadata": {
        "id": "jH9qFJD9Xdsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HistoryQuiz():\n",
        "\n",
        "    def create_history_question(self,topic):\n",
        "        '''\n",
        "        This method should output a historical question about the topic that has a date as the correct answer.\n",
        "        For example:\n",
        "\n",
        "            \"On what date did World War 2 end?\"\n",
        "\n",
        "        '''\n",
        "        system_template = \"You are an AI assistant who outputs a historical question that has a date as the correct answer given a topic.\"\n",
        "        system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
        "        human_template = \"The topic is {topic}\"\n",
        "        human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
        "        chat_prompt  = ChatPromptTemplate.from_messages([human_message_prompt, system_message_prompt])\n",
        "        prompt = chat_prompt.format_prompt(topic = topic).to_messages()\n",
        "        question = chat(prompt).content\n",
        "        return question\n",
        "\n",
        "    def get_AI_answer(self,question):\n",
        "        '''\n",
        "        This method should get the answer to the historical question from the method above.\n",
        "        Note: This answer must be in datetime format! Use DateTimeOutputParser to confirm!\n",
        "\n",
        "        September 2, 1945 --> datetime.datetime(1945, 9, 2, 0, 0)\n",
        "        '''\n",
        "        output_parser = DatetimeOutputParser()\n",
        "        template_text = \"{request} {format_instructions}\"\n",
        "        human_prompt = HumanMessagePromptTemplate.from_template(template_text)\n",
        "        system_prompt = SystemMessagePromptTemplate.from_template(\"You always reply to questions only in date time pattern\") # Fix number 1\n",
        "        chat_prompt = ChatPromptTemplate.from_messages([human_prompt])\n",
        "        model_request = chat_prompt.format_prompt(request = question, format_instructions = output_parser.get_format_instructions()).to_messages()\n",
        "        correct_datetime = output_parser.parse(chat(model_request, temperature=1).content)\n",
        "\n",
        "        # Saving the system prompt\n",
        "        # print(\"Saving the system prompt....\")\n",
        "        # system_prompt.save(\"system_prompt.json\")\n",
        "        prompt =  PromptTemplate(template=template_text, input_variables = [\"request\", \"format_instructions\"])\n",
        "        prompt.save(\"myprompts.json\")\n",
        "\n",
        "\n",
        "        # # Saving the human prompt\n",
        "        # print(\"Saving the human prompt....\")\n",
        "        # human_prompt.save(\"human_prompt.json\")\n",
        "\n",
        "\n",
        "        return correct_datetime\n",
        "\n",
        "    def get_user_answer(self,question):\n",
        "        '''\n",
        "        This method should grab a user answer and convert it to datetime. It should collect a Year, Month, and Day.\n",
        "        You can just use input() for this.\n",
        "        '''\n",
        "        print(question)\n",
        "\n",
        "\n",
        "        # Get the year, month, and day from the user\n",
        "        year = int(input(\"Enter the year: \"))\n",
        "        month = int(input(\"Enter the month (1-12): \"))\n",
        "        day = int(input(\"Enter the day (1-31): \"))\n",
        "\n",
        "        # Create a datetime object\n",
        "        user_datetime = datetime(year, month, day)\n",
        "\n",
        "\n",
        "        return user_datetime\n",
        "\n",
        "\n",
        "    def check_user_answer(self,user_answer,ai_answer):\n",
        "        '''\n",
        "        Should check the user answer against the AI answer and return the difference between them\n",
        "        '''\n",
        "        # print or return the difference between the answers here!\n",
        "        print(\"The difference between AI answer and User answer: \", user_answer - ai_answer)\n",
        "\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "fYilqPckXedU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_bot = HistoryQuiz()"
      ],
      "metadata": {
        "id": "GlSiyLbFXhaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = quiz_bot.create_history_question(topic='World War 2')"
      ],
      "metadata": {
        "id": "BqatL50zXj21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_answer = quiz_bot.get_AI_answer(question)"
      ],
      "metadata": {
        "id": "m7IIaEWLXljY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_answer = quiz_bot.get_user_answer(question)"
      ],
      "metadata": {
        "id": "R56uuh15XnMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quiz_bot.check_user_answer(user_answer,ai_answer)"
      ],
      "metadata": {
        "id": "wGtn-YFAXo57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oUITdNVjXtLZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvbTznTqy2YhIGgXivq2yh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}